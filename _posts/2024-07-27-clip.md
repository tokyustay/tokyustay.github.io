---
title: "[쇼츠논문리뷰] CLIP : Learning Transferable Visual Models From Natural Language Supervision"
date: 2024-07-27 10:54:53 +09:00
categories: [ai, paper review]
tags:
  [
    ai paper review,
    CLIP
  ]
---

**선요약**


`CLIP` : `Contrastive Language Image Pretraining`로, Pre-trained `Text encoder`와 `Image encoder`에서 생성된 `embedding`끼리 cosine similarity를 positive pair끼리는 최대화, negative pair끼리는 최소화시켜 `Multimodal` 구현

`WIT` : `WebImageText`로, Wikipedia와 웹을 이용해 긁어보은 대용량 Vision Language 데이터셋 구축

`Contribution` : Natural Language Supervision에서 효과적으로 학습가능한 Multimodal 제안

<br/>
<br/>

# **CLIP**

![clip](https://github.com/openai/CLIP/blob/main/CLIP.png?raw=true)

Pre-trained Text encoder와 Image encoder에서 생성된 embedding끼리 cosine similarity를 positive pair끼리는 최대화, negative pair끼리는 최소화시키는 Contrastive learning

**예시**

- A : (I1, T1 : cat image, "a photo of a cat")
- B : (I2, T2 : dog image, "a photo of a dog")
- C : (I3, T3 : man image, "a photo of a man")

- **cat image - "a photo of a cat" : cosine similarity 최대화**
- cat image - "a photo of a dog" : cosine similarity 최소화
- cat image - "a photo of a man" : cosine similarity 최소화


- dog image - "a photo of a cat" : cosine similarity 최소화
- **dog image - "a photo of a dog" : cosine similarity 최대화**
- dog image - "a photo of a man" : cosine similarity 최소화

- man image - "a photo of a cat" : cosine similarity 최소화
- man image - "a photo of a dog" : cosine similarity 최소화
- **man image - "a photo of a man" : cosine similarity 최대화**

이로써 웹에서 긁어모은 대용량 데이터셋을 활용 가능한 멀티모달이 완성되었다
