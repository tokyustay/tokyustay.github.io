---
title: "[선형대수] lp norms"
date: 2024-05-14 09:48:56 +09:00
categories: [ai, study]
tags:
  [
    ai,
    study,
    norm,
    선형대수
  ]
math: true
---

**선요약**

`Lp norm` : 벡터 공간에서 벡터의 크기 또는 길이를 측정하는 방법, p는 norm의 차수

| 노름 | 정의 | 주요 용도 | 특징 |
| --- | --- | --- | --- |
| L0 노름 | 0이 아닌 원소의 개수 | 희소성 측정 | 직접 최적화 어려움 |
| L1 노름 | 원소 절대값의 합 | 희소성 촉진 | 맨해튼 거리 |
| L2 노름 | 원소 제곱합의 제곱근 | 일반적인 거리 측정 | 유클리드 거리 |

<br/>
<br/>

# **L0 norm**

벡터에서 0이 아닌 원소의 개수를 세는 함수

$ \|x\|_0 = \text{number of non-zero elements in } x $

- 실제로는 "norm"의 수학적 정의를 엄격히 따르지 않음.
- 희소성(sparsity)을 측정하는 데 사용.
- 최적화 문제에서 직접 사용하기 어렵지만, 희소성 제약을 추가하는 데 자주 사용됨.

```python
import numpy as np

x = np.array([1, 0, 2, 0, 0, 3])
l0_norm = np.sum(x != 0)  # 3
```

# **L1 norm**

벡터의 각 원소의 절대값의 합


$ \|x\|_1 = \sum_{i=1}^{n} |x_i| $


- Taxicab norm 또는 manhattan norm라고도 불림.
- 요소의 값 변화 파악할 수 있음.
- L1 regularization과 (예: Lasso) computer vision 분야에서 사용함.

```python
x = np.array([1, -2, 3])
l1_norm = np.sum(np.abs(x))  # 6
```

# **L2 norm**

벡터의 각 원소의 제곱의 합의 제곱근


$ \|x\|_2 = \sqrt{\sum_{i=1}^{n} x_i^2} $


- Euclidean norm라고도 불림.
- L2 regularization, KNN알고리즘, K-means 알고리즘등에서 사용
- 벡터의 크기와 방향을 유지하는데 유리.

```python
x = np.array([1, -2, 3])
l2_norm = np.sqrt(np.sum(x**2))  # 3.7416573867739413
```


