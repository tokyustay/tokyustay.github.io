---
title: "[선형대수] lp norms"
date: 2024-05-14 09:48:56 +09:00
categories: [ai, study]
tags:
  [
    ai,
    study,
    norm,
    선형대수
  ]
math: true
---

**선요약**

`Lp norm` : 벡터 공간에서 벡터의 크기 또는 길이를 측정하는 방법, p는 norm의 차수

$$
\| \mathbf{x} \|_p = \left( \sum_{i=1}^{n} |x_i|^p \right)^{\frac{1}{p}}
$$

| 노름 | 정의 | 주요 용도 | 특징 |
| --- | --- | --- | --- |
| L0 노름 | 0이 아닌 원소의 개수 | 희소성 측정 | 희소성 제약에 사용 |
| L1 노름 | 원소 절대값의 합 | 희소성 촉진 | 맨해튼 거리 |
| L2 노름 | 원소 제곱합의 제곱근 | 일반적인 거리 측정 | 유클리드 거리 |
| L∞ 노름 | 절대값이 가장 큰 원소의 값 | 벡터의 가장 큰 절대값을 파악 | 맥시멈 거리 |

<br/>
<br/>

# **L0 norm**

<br/>

벡터에서 0이 아닌 원소의 개수를 세는 함수

<br/>

$$ \|x\|_0 = \text{number of non-zero elements in } x $$

<br/>

- 실제로는 "norm"의 수학적 정의를 엄격히 따르지 않음
- 희소성(sparsity)을 측정하는 데 사용
- 최적화 문제에서 직접 사용하기 어렵지만, 희소성 제약을 추가하는 데 자주 사용됨

```python
import numpy as np

x = np.array([1, 0, 2, 0, 0, 3])
l0_norm = np.sum(x != 0)  # 3
```

<br/>

# **L1 norm**

<br/>

벡터의 각 원소의 절대값의 합

<br/>

$$ \|x\|_1 = \sum_{i=1}^{n} |x_i| $$

<br/>

- Taxicab norm 또는 manhattan norm라고도 불림
- 요소의 값 변화 파악할 수 있음
- L1 regularization과 (예: Lasso) computer vision 분야에서 사용함

```python
x = np.array([1, -2, 3])
l1_norm = np.sum(np.abs(x))  # 6
```

<br/>

# **L2 norm**

<br/>

벡터의 각 원소의 제곱의 합의 제곱근

<br/>

$$ \|x\|_2 = \sqrt{\sum_{i=1}^{n} x_i^2} $$

<br/>

- Euclidean norm라고도 불림
- L2 regularization, KNN알고리즘, K-means 알고리즘등에서 사용
- 벡터의 크기와 방향을 유지하는데 유리

```python
x = np.array([1, -2, 3])
l2_norm = np.sqrt(np.sum(x**2))  # 3.7416573867739413
```


# **L∞ norm**

<br/>

벡터에서 절대값이 가장 큰 원소의 값

<br/>

$$ \|x\|_\infty = \max_i |x_i| $$

<br/>

- Maximum norm 또는 Chebyshev norm이라고도 불림
- 벡터의 가장 큰 절대값을 파악할 수 있음
- 컴퓨터 과학과 제어 이론에서 사용됨

```python
x = np.array([1, -2, 3])
linf_norm = np.max(np.abs(x))  # 3
```